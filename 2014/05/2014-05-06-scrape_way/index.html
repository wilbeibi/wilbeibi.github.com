<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="My experience on how to scrape data from web."><meta name="keywords" content="notes"><meta name="author" content="wilbeibi"><meta name="copyright" content="wilbeibi"><title>Scrape data the right way Part:1 | Gradient Ascent</title><link rel="shortcut icon" href="/images/favicon.ico?v=2"><link rel="stylesheet" href="/css/index.css?version=1.9.1"><link rel="stylesheet" href="/css/custom.css?version=1.9.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"N3W10X795S","apiKey":"ed0a732eec07d11478a1d5c38c6a82b4","indexName":"wilbeibi_blog","hits":{"per_page":10},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '8.0.0'
} </script><meta name="generator" content="Hexo 8.0.0"><link rel="alternate" href="/atom.xml" title="Gradient Ascent" type="application/atom+xml">
</head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Why-lxml"><span class="toc-number">1.</span> <span class="toc-text">Why lxml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Example-Grab-data-from-Craglist"><span class="toc-number">2.</span> <span class="toc-text">Example: Grab data from Craglist</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">wilbeibi</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">23</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">9</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">1</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/images/curve.webp)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Gradient Ascent</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">Scrape data the right way Part:1</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2014-05-06</time></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>There is frequently a need to scrape data. Obviously, Python is a good choice for this. The famous libraries like <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a> provides a bunch of functions to do these stuffs. But personally, I prefer <a href="http://lxml.de/">lxml</a>.</p>
<h2 id="Why-lxml"><a href="#Why-lxml" class="headerlink" title="Why lxml"></a>Why lxml</h2><p>There already has some <a href="http://stackoverflow.com/questions/4967103/beautifulsoup-and-lxml-html-what-to-prefer#">comparison</a> about pros and cons of each library. As <a href="http://lxml.de/elementsoup.html">lxml document</a> said:</p>
<blockquote>
<p>BeautifulSoup uses a different parsing approach. It is not a real HTML parser but uses regular expressions to dive through tag soup. It is therefore more forgiving in some cases and less good in others. It is not uncommon that lxml&#x2F;libxml2 parses and fixes broken HTML better, but BeautifulSoup has superior support for encoding detection. <strong>It very much depends on the input which parser works better.</strong><br>… …<br>The downside of using this parser is that it is <strong>much slower than</strong> the HTML parser of lxml. <strong>So if performance matters, you might want to consider using soupparser only as a fallback for certain cases.</strong></p>
</blockquote>
<p>In short: lxml is faster when parsing well-formed web page.</p>
<h2 id="Example-Grab-data-from-Craglist"><a href="#Example-Grab-data-from-Craglist" class="headerlink" title="Example: Grab data from Craglist"></a>Example: Grab data from Craglist</h2><p>This is a common scenario. First get links of each entries in a <code>index</code> page.</p>
<p>For example, find all housing in <a href="http://losangeles.craigslist.org/hhh/index.html">http://losangeles.craigslist.org/hhh/index.html</a>. In Chrome, Inspect Element, get XPath link from one link:<br><img src="http://i.imgur.com/M5twZ1U.png"></p>
<p>The xpath is <code>/*[@id=&quot;toc_rows&quot;]/div[2]/p[1]/span[2]/a/@href</code>, from p[1] to p[100]. Save these links to a file <code>crag_link.txt</code>. </p>
<pre><code>from lxml import html
import requests
 
with open(&#39;crag_link.txt&#39;, &#39;a&#39;) as f:
    for i in range(0, 1000, 100):
        pg = &#39;http://losangeles.craigslist.org/hhh/index&#39; + str(i) + &#39;.html&#39;
        src = requests.get(pg)
        if src.status_code == 404:
            sys.exit(1)
        tree = html.fromstring(src.text)
        print &#39;Get page&#39;, i
        for j in range(1, 100+1):
            x_link = &#39;//*[@id=&quot;toc_rows&quot;]/div[2]/p[&#39; + str(j) + &#39;]/span[2]/a/@href&#39;
            links = tree.xpath(x_link)
            for ln in links:
                f.write( &#39;http://losangeles.craigslist.org&#39; + ln + &#39;\n&#39;)
        
    f.close()
</code></pre>
<p>Click into one of the page, for instance, we want to get post id, copy xpath<br>like <code>//*[@id=&quot;pagecontainer&quot;]/section/section[2]/div[2]/p[1]</code>. According to <a href="http://www.w3.org/TR/xpath/">XPath syntax</a>, these path add suffix <code>/text()</code> is what we need.</p>
<pre><code>try:
    post_id = tree.xpath(&#39;//*[@id=&quot;pagecontainer&quot;]/section/section[2]/div[2]/p[1]/text()&#39;)
except:
    # Handle Error
</code></pre>
<p>The reason we add try&#x2F;catch block here is to prevent missing data. Wait a second, what if we have 30 attribute to scrape, do we need to write try&#x2F;catch 30 times. Definitely no. Wrap them into a function might be a good idea. BTW, hardcode xpath into program is not a good idea, by writing a function, we can pass it as a parameter(Or even better, store attribute names and xpaths in a dictionary).</p>
<pre><code>def get_attr(tree, xps):
    return attr_name = tree.xpath(xps)
 
&#39;&#39;&#39; 
xps_dict look like: 
{&#39;post_id&#39;:&#39;//*&lt;somehing&gt;/p[1]/text()&#39;,&#39;post_time&#39;:&#39;//*&lt;somehing&gt;/p[1]/text()&#39;}
&#39;&#39;&#39;
for a, x in xps_dict.iteritems():
    attr[a] = get_attr(tree, x)
</code></pre>
<p>For the Part 2, I will carry on, talk about encoding problem, prevent duplicates and so forth.</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">wilbeibi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://wilbeibi.com/2014/05/2014-05-06-scrape_way/">http://wilbeibi.com/2014/05/2014-05-06-scrape_way/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/notes/">notes</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2014/07/2014-07-17-dropbox-coding/"><i class="fa fa-chevron-left">  </i><span>Collaborative programming with Dropbox</span></a></div><div class="next-post pull-right"><a href="/2014/03/2014-03-05-macandfriend/"><span>Mac程序员和他的朋友们</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(/images/curve.webp)"><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2025 By wilbeibi</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/lib/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.1"></script><script src="/js/fancybox.js?version=1.9.1"></script><script src="/js/sidebar.js?version=1.9.1"></script><script src="/js/copy.js?version=1.9.1"></script><script src="/js/fireworks.js?version=1.9.1"></script><script src="/js/transition.js?version=1.9.1"></script><script src="/js/scroll.js?version=1.9.1"></script><script src="/js/head.js?version=1.9.1"></script><script src="/js/search/algolia.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="algolia-search"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>